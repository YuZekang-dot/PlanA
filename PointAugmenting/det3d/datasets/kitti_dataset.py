import os
import pickle
import numpy as np
import cv2
from pathlib import Path

from det3d.datasets.custom import PointCloudDataset
from det3d.datasets.registry import DATASETS


@DATASETS.register_module
class KittiDataset(PointCloudDataset):
    """KITTI-radar style dataset with single camera and 4D radar points.

    Expects info pkl generated by tools.create_data.kitti_data_prep().
    This implementation follows the NuScenesDataset style and supports optional image branch.
    """

    NumPointFeatures = 8  # [x, y, z, D, P, R, A, E]

    def __init__(
        self,
        info_path,
        root_path,
        use_img=True,
        cfg=None,
        pipeline=None,
        class_names=None,
        test_mode=False,
        **kwargs,
    ):
        if class_names is None:
            class_names = ["Car", "Cyclist", "Truck"]

        # Load infos BEFORE calling super().__init__ because parent _set_group_flag calls len(self)
        self._info_path = info_path
        with open(self._info_path, "rb") as f:
            self._infos = pickle.load(f)
        self._root_path = Path(root_path)
        self._class_names = class_names
        self.test_mode = test_mode
        self.use_img = use_img
        self._num_point_features = KittiDataset.NumPointFeatures

        # Now safely call parent to set pipeline and flags
        super().__init__(root_path, info_path, pipeline, test_mode=test_mode, class_names=class_names)

        # image norm used by DLASeg backbone
        if use_img:
            self.mean = np.array([0.40789654, 0.44719302, 0.47026115], dtype=np.float32).reshape(1, 1, 3)
            self.std = np.array([0.28863828, 0.27408164, 0.27809835], dtype=np.float32).reshape(1, 1, 3)
            self.target_size = (3, 448, 800)

    def __len__(self):
        return len(self._infos)

    def input_transform(self, image):
        image = image.astype(np.float32) / 255.0
        image -= self.mean
        image /= self.std
        return image

    def get_image(self, image):
        image = cv2.resize(image, (800, 450))
        image = self.input_transform(image)
        image = image.transpose((2, 0, 1))
        image = image[:, :448, :800]
        return image.astype(np.float32).copy()

    def get_sensor_data(self, idx):
        info = self._infos[idx]
        res = {
            "lidar": {"type": "lidar", "points": None, "annotations": None},
            "metadata": {"image_prefix": self._root_path, "num_point_features": self._num_point_features, "token": info["token"]},
            "camera": {"name": ["CAM_FRONT"], "cam_paths": {"CAM_FRONT": info.get("image", "")}},
            "calib": {"P0": info["calib"]["P0"], "R0_rect": info["calib"]["R0_rect"], "Tr_velo_to_cam": info["calib"]["Tr_velo_to_cam"]},
            "mode": "val" if self.test_mode else "train",
        }

        if self.use_img:
            img = cv2.imread(info["image"]) if os.path.exists(info["image"]) else None
            if img is None:
                img = np.zeros((480, 640, 3), dtype=np.uint8)
            res["img"] = np.stack([img], axis=0)  # keep shape consistent with fusion code

        # Pack annotations if available (camera frame). For GT-DB, test_mode=True but we still need annos.
        if ("gt_boxes_camera" in info):
            res["lidar"]["annotations"] = {
                "boxes": info["gt_boxes_camera"].astype(np.float32),
                "names": info["gt_names"],
            }
            if self.use_img:
                N = len(info["gt_boxes_camera"])
                res["camera"]["annotations"] = {
                    # For KITTI we have a single camera; keep shape (N, 1)
                    "avail_2d": np.ones((N, 1), dtype=np.bool_),
                    "boxes_2d": info["boxes_2d"].astype(np.int32)[..., None, :].repeat(6, axis=1)[:, :1, :],
                    "depths": info["depths"].astype(np.float32)[:, None],
                }

        data, _ = self.pipeline(res, info)

        if self.use_img:
            data["img"] = [self.get_image(im) for im in data["img"]]
            data["img"] = np.stack(data["img"], axis=0)

        return data

    def __getitem__(self, idx):
        return self.get_sensor_data(idx)

    @property
    def ground_truth_annotations(self):
        if self.test_mode:
            return None
        gt = []
        for info in self._infos:
            if "gt_boxes_camera" not in info:
                gt.append({})
                continue
            names = np.array(info["gt_names"]) if not isinstance(info["gt_names"], np.ndarray) else info["gt_names"]
            loc_dim_rot = info["gt_boxes_camera"].astype(np.float32)
            gt.append({
                "bbox": np.tile(np.array([[0, 0, 50, 50]]), [len(names), 1]),
                "alpha": np.full(len(names), -10, dtype=np.float32),
                "occluded": np.zeros(len(names), dtype=np.int32),
                "truncated": np.zeros(len(names), dtype=np.float32),
                "name": names,
                "location": loc_dim_rot[:, :3],
                "dimensions": loc_dim_rot[:, 3:6],
                "rotation_y": loc_dim_rot[:, 6],
                "token": info["token"],
            })
        return gt

    def evaluation(self, detections, output_dir=None, testset=False):
        """
        Evaluate predictions with 3D IoU-based metrics on the validation set.

        Metrics:
        - mean_3d_iou: 平均3D IoU（只统计成功匹配的GT↔预测对）。
        - acc@0.5: IoU>=0.5 的正确率 = 正确匹配的GT数量 / 总GT数量。
        - mAP@0.5: 以IoU阈值0.5计算的mAP（对每个类别计算AP再宏平均）。

        返回 result_dict 以便 Trainer.logger 写入日志。
        """
        import torch
        from det3d.ops.iou3d_nms.iou3d_nms_utils import boxes_iou3d_gpu

        iou_thresh = 0.5
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        # 建立 token -> info 的索引，便于取标注与标定
        token_to_info = {info["token"]: info for info in self._infos}

        # 将相机系 GT 框转换为激光雷达系，与预测保持一致
        def cam_boxes_to_lidar(boxes_cam, calib):
            # boxes_cam: [N,7] = [x,y,z,l,w,h,ry] 摄像头rect坐标（底部中心）
            import numpy as np
            R0 = np.eye(4, dtype=np.float32)
            R0[:3, :3] = np.array(calib.get("R0_rect", np.eye(3)), dtype=np.float32)
            Tr = np.eye(4, dtype=np.float32)
            Tr[:3, :4] = np.array(calib["Tr_velo_to_cam"], dtype=np.float32)
            Tr_inv = np.linalg.inv(Tr)
            R0_inv = np.linalg.inv(R0)
            Rt = Tr_inv @ R0_inv
            R_only = Rt[:3, :3]
            centers_cam = boxes_cam[:, :3].astype(np.float32)
            dims_lwh = boxes_cam[:, 3:6].astype(np.float32)
            ry = boxes_cam[:, 6].astype(np.float32)
            # 将相机底部中心改为几何中心（相机坐标y向下）
            centers_cam_true = centers_cam.copy()
            centers_cam_true[:, 1] -= dims_lwh[:, 2] / 2.0
            centers_cam_h = np.concatenate([centers_cam_true, np.ones((centers_cam_true.shape[0], 1), dtype=np.float32)], axis=1)
            centers_velo = (Rt @ centers_cam_h.T).T[:, :3]
            # 朝向转换
            dir_cam = np.stack([np.sin(ry), np.zeros_like(ry), np.cos(ry)], axis=1)
            dir_velo = (R_only @ dir_cam.T).T
            yaw_lidar = np.arctan2(dir_velo[:, 1], dir_velo[:, 0])
            # 维度从 [l,w,h] -> [w,l,h]
            w = dims_lwh[:, 1]
            l = dims_lwh[:, 0]
            h = dims_lwh[:, 2]
            # 目标格式与预测一致: [x,y,z, w,l,h, yaw]
            boxes_lidar7 = np.stack([centers_velo[:, 0], centers_velo[:, 1], centers_velo[:, 2], w, l, h, yaw_lidar], axis=1).astype(np.float32)
            return boxes_lidar7

        # 统计量
        total_gt = 0
        matched_gt = 0
        iou_sum = 0.0
        iou_cnt = 0

        # 为mAP累计：按类别收集 (score, is_tp) 序列 以及每类GT总数
        num_classes = len(self._class_names) if self._class_names is not None else 0
        per_class_records = {c: [] for c in range(num_classes)}
        per_class_gt_count = {c: 0 for c in range(num_classes)}

        # 遍历每个样本（按token）
        for token, det in detections.items():
            info = token_to_info.get(token, None)
            if info is None:
                continue
            # 预测（确保与IoU算子一致：必须在CUDA上）
            pred_boxes = det["box3d_lidar"].detach().to(device)
            pred_labels = det["label_preds"].detach().cpu().numpy().astype(np.int64)
            pred_scores = det["scores"].detach().cpu().numpy().astype(np.float32)

            # GT（相机->激光雷达）
            if "gt_boxes_camera" not in info or len(info["gt_boxes_camera"]) == 0:
                # 没有GT，但要记录FP到mAP序列
                for lb, sc in zip(pred_labels, pred_scores):
                    if lb in per_class_records:
                        per_class_records[lb].append((sc, 0))
                continue

            gt_boxes_cam = info["gt_boxes_camera"].astype(np.float32)
            gt_names = info["gt_names"]
            gt_boxes_lidar = cam_boxes_to_lidar(gt_boxes_cam, info["calib"])  # [N,7] [x,y,z,w,l,h,yaw]

            # 逐类匹配
            used_gt = set()
            total_gt += len(gt_boxes_lidar)
            # 为每类计数GT
            if self._class_names is not None:
                for name in gt_names:
                    if name in self._class_names:
                        per_class_gt_count[self._class_names.index(name)] += 1

            for c in range(num_classes):
                # 取该类的预测与GT
                gt_mask_c = np.array([n == self._class_names[c] for n in gt_names])
                gt_c_np = gt_boxes_lidar[gt_mask_c]
                gt_c = torch.from_numpy(gt_c_np).to(device) if gt_c_np.size > 0 else torch.zeros((0, 7), dtype=torch.float32, device=device)

                pred_mask_c_np = (pred_labels == c)
                pred_mask_c = torch.from_numpy(pred_mask_c_np).to(device)
                boxes_c = pred_boxes[pred_mask_c]
                scores_c = pred_scores[pred_mask_c_np]

                if gt_c.shape[0] == 0 and boxes_c.shape[0] == 0:
                    continue

                if gt_c.shape[0] == 0:
                    # 该类全是FP
                    for sc in scores_c:
                        per_class_records[c].append((float(sc), 0))
                    continue

                if boxes_c.shape[0] == 0:
                    # 该类只有GT，无预测 => 这些会体现在召回里
                    continue

                # 计算IoU矩阵 (P, G) — 该CUDA扩展要求输入为CUDA张量
                if device.type != "cuda":
                    # 无CUDA时跳过，避免崩溃（返回0 IoU影响mAP/acc）。
                    ious_np = np.zeros((boxes_c.shape[0], gt_c.shape[0]), dtype=np.float32)
                else:
                    ious = boxes_iou3d_gpu(boxes_c.float().contiguous(), gt_c[:, :7].float().contiguous())  # (P, G)
                    ious_np = ious.detach().cpu().numpy()

                # 按分数从高到低贪心匹配用于 mAP 统计
                order = np.argsort(-scores_c)
                gt_taken = np.zeros(gt_c.shape[0], dtype=bool)
                for pi in order:
                    giou = ious_np[pi]
                    best_gt = int(giou.argmax())
                    best_iou = float(giou[best_gt])
                    if best_iou >= iou_thresh and not gt_taken[best_gt]:
                        per_class_records[c].append((float(scores_c[pi]), 1))
                        gt_taken[best_gt] = True
                        matched_gt += 1
                        iou_sum += best_iou
                        iou_cnt += 1
                    else:
                        per_class_records[c].append((float(scores_c[pi]), 0))

        # 计算最终指标
        acc = (matched_gt / total_gt) if total_gt > 0 else 0.0
        mean_iou = (iou_sum / iou_cnt) if iou_cnt > 0 else 0.0

        # 计算每类AP与mAP
        def compute_ap(sorted_scores_tp):
            # sorted by score desc: list of (score, tp)
            if len(sorted_scores_tp) == 0:
                return 0.0
            tp = np.array([t for _, t in sorted_scores_tp], dtype=np.float32)
            fp = 1.0 - tp
            tp_cum = np.cumsum(tp)
            fp_cum = np.cumsum(fp)
            recalls = tp_cum / max(1, pos_num)
            precisions = tp_cum / np.maximum(tp_cum + fp_cum, 1e-8)
            # 常用的PR曲线插值AP（VOC 07+ style: integrate all unique recall points）
            # 使precision单调递减
            for i in range(len(precisions) - 2, -1, -1):
                precisions[i] = max(precisions[i], precisions[i + 1])
            # 面积
            ap = 0.0
            prev_r = 0.0
            for p, r in zip(precisions, recalls):
                if r > prev_r:
                    ap += p * (r - prev_r)
                    prev_r = r
            return float(ap)

        per_class_ap = {}
        aps = []
        for c in range(num_classes):
            pos_num = per_class_gt_count.get(c, 0)
            records = per_class_records.get(c, [])
            # 按分数降序
            records.sort(key=lambda x: -x[0])
            ap = compute_ap(records) if pos_num > 0 else 0.0
            per_class_ap[self._class_names[c] if self._class_names is not None else str(c)] = ap
            if pos_num > 0:
                aps.append(ap)
        map50 = float(np.mean(aps)) if len(aps) > 0 else 0.0

        result = {
            "results": {
                "acc@0.5": acc,
                "mAP@0.5": map50,
                "mean_3d_iou": mean_iou,
                "per_class_ap@0.5": per_class_ap,
                "total_gt": int(total_gt),
                "matched_gt": int(matched_gt),
            }
        }

        return result, None
